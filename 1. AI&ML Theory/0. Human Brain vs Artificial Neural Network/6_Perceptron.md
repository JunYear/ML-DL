# 퍼셉트론의 구조
- 퍼셉트론은 본래 F.Rosenblatt가 제안한 것으로 수용층, 연합층, 반응층의 3계층 구조로 되어 있음.
	- 수용층: 외부의 입력을 받아들여서 연합층에 전달하는 기능을 수행
	- 연합층: 수용층에서의 입력을 반응층에 전달하는 기능을 수행
	- 반응층: 입력 가중합을 구하여 최종 출력을 내보내는 기능을 수행
- Rosenblatt의 퍼셉트론에서 수용층과 연합층을 통합하여 단층 신경망 구조로 대체한 것을 **퍼셉트론(Perceptron)** 이라 함.
- 분류에 사용되는 다층 신경망을 모두 다층 퍼셉트론(MLP, Multi_Layer Perceptron)이라고 부름.
- 퍼셉트론의 입력 가중합 NET은 다음과 같음.

$NET = xw^T$
- 퍼셉트론은 양극성 계단 함수를 활성화 함수로 사용하므로 출력 $y$는 다음과 같이 표현 가능함.
- T는 임계치를 뜻함.

$$y = f(NET) = \begin{cases} +1: \text{NET > T} \\ 0: \text{NET = T} \\ -1: \text{NET < T} \end{cases}$$

## 다중 출력 퍼셉트론 (NLP)
- 단층 퍼셉트론은 출력층의 뉴런이 단지 1개이므로 2가지 유형의 패턴 분류만이 가능함.
- 여러 가지 출력이 요구되는 경우에는 다중 출력 퍼셉트론을 사용할 수 있음.
- 출력층 $m$번째 뉴런의 입력 가중합 $NET_m$과 출력 $y_m$은 다음과 같이 표현 가능

$$NET_m = x_1w_m1 + ... + x_nw_{mn} = [x_1 ... x_n]\begin{bmatrix}w_{m1} \\ \vdots \\ w_{mn} \end{bmatrix}$$
$$$y_m = f(NET_m) = \begin{cases} +1: \text{NET > T} \\ 0: \text{NET = T} \\ -1: \text{NET < T} \end{cases}$$

# 퍼셉트론의 학습 알고리즘

퍼셉트론을 특정 응용에 활용하기 위해서는 미리 학습이 수행되어야 함.
- 1 단계: 연결 강도(가중치)를 임의의 작은 값으로 초기화, 학습 시킬 $p$개의 학습 패턴쌍 (입력 패턴 $x$, 목표치 $d$)들을 선정
- 2 단계: 학습률 $\eta$ 를 결정. 퍼셉트론에서는 일반적으로 학습률 $\eta$ 를 0에서 1 사이의 값으로 변경.
- 3 단계: 연결 강도를 변경하기 위해 학습 패턴쌍들을 차례로 입력.
- 4 단계: 입력되는 학습 패턴의 가중합 $NET$을 구한 다음, 임계치가 $T$인 양극성 계단 함수를 활성화 함수로 사용하여 출력 $y$를 구함.

$NET = xw^T$

$$y = \begin{cases} +1: \text{NET >T} \\ 0: \text{NET = T} \\ -1: \text{NET < T} \end{cases}$$

- 5 단계: 출력 $y$와 목표치 d를 비교함. 만약 출력과 목표치가 동일한 경우에는 연결 강도를 변경하지 않고, 출력이 목표치와 다른 경우에만 연결 강도를 변경함.
- 6 단계: 연결 강도 변화량 $\Delta w$를 계산하여 다음 학습 단계에 사용될 연결 강도 $w^{k+1}$를 구함.

$\Delta w = \eta(d-y)X$

$w^{k+1} = w^k + \Delta w$

- 7 단계: 학습 패턴쌍을 반복 입력하여 연결 강도를 갱신하며, 더 이상 연결 강도가 변하지 않으면 학습을 종료함.