{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JunYear/ML-DL/blob/main/2.%20AI%26ML%20Hands-On/%5BHands_On%5D_Image_Classification_Using_AutoKeras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb1w_IEKmbeT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd48b671-72ff-428d-ee6a-57a20f7d824c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autokeras\n",
            "  Downloading autokeras-2.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from autokeras) (24.1)\n",
            "Collecting keras-tuner>=1.4.0 (from autokeras)\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting keras-nlp>=0.8.0 (from autokeras)\n",
            "  Downloading keras_nlp-0.15.1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from autokeras) (3.4.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from autokeras) (0.1.8)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (0.4.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-nlp>=0.8.0->autokeras) (2024.9.11)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras-nlp>=0.8.0->autokeras) (0.3.0)\n",
            "Collecting tensorflow-text (from keras-nlp>=0.8.0->autokeras)\n",
            "  Downloading tensorflow_text-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner>=1.4.0->autokeras) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner>=1.4.0->autokeras)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-nlp>=0.8.0->autokeras) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.0.0->autokeras) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.4.0->autokeras) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.4.0->autokeras) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.4.0->autokeras) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.4.0->autokeras) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->autokeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->autokeras) (2.18.0)\n",
            "Requirement already satisfied: tensorflow<2.18,>=2.17.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras-nlp>=0.8.0->autokeras) (2.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->autokeras) (0.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (2.17.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (0.44.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (2.1.5)\n",
            "Downloading autokeras-2.0.0-py3-none-any.whl (122 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.7/122.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras_nlp-0.15.1-py3-none-any.whl (548 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.4/548.4 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Downloading tensorflow_text-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kt-legacy, keras-tuner, tensorflow-text, keras-nlp, autokeras\n",
            "Successfully installed autokeras-2.0.0 keras-nlp-0.15.1 keras-tuner-1.4.7 kt-legacy-1.0.5 tensorflow-text-2.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install autokeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBziqrfJmbeU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.datasets import mnist\n",
        "\n",
        "import autokeras as ak"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA74Fr_4mbeU"
      },
      "source": [
        "## A Simple Example\n",
        "The first step is to prepare your data. Here we use the MNIST dataset as an\n",
        "example\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5nBXslumbeU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f331554e-5db2-4fba-f24e-830df0023908"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "(100, 28, 28)\n",
            "(100,)\n",
            "[5 0 4]\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train[:100]\n",
        "y_train = y_train[:100]\n",
        "x_test = x_test[:100]\n",
        "y_test = y_test[:100]\n",
        "print(x_train.shape)  # (60000, 28, 28)\n",
        "print(y_train.shape)  # (60000,)\n",
        "print(y_train[:3])  # array([7, 2, 1], dtype=uint8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aETszJEumbeV"
      },
      "source": [
        "The second step is to run the ImageClassifier.\n",
        "It is recommended have more trials for more complicated datasets.\n",
        "This is just a quick demo of MNIST, so we set max_trials to 1.\n",
        "For the same reason, we set epochs to 10.\n",
        "You can also leave the epochs unspecified for an adaptive number of epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "143pK7TGmbeV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89453f3f-33e0-442f-a4f7-6087649e5c8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 Complete [00h 00m 12s]\n",
            "val_loss: 2.0414092540740967\n",
            "\n",
            "Best val_loss So Far: 2.0414092540740967\n",
            "Total elapsed time: 00h 00m 12s\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.0997 - loss: 2.3009\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "[['3']\n",
            " ['0']\n",
            " ['1']\n",
            " ['0']\n",
            " ['4']\n",
            " ['1']\n",
            " ['3']\n",
            " ['4']\n",
            " ['4']\n",
            " ['9']\n",
            " ['0']\n",
            " ['4']\n",
            " ['9']\n",
            " ['0']\n",
            " ['1']\n",
            " ['3']\n",
            " ['0']\n",
            " ['3']\n",
            " ['3']\n",
            " ['4']\n",
            " ['9']\n",
            " ['6']\n",
            " ['4']\n",
            " ['0']\n",
            " ['4']\n",
            " ['0']\n",
            " ['3']\n",
            " ['4']\n",
            " ['0']\n",
            " ['3']\n",
            " ['3']\n",
            " ['1']\n",
            " ['3']\n",
            " ['0']\n",
            " ['3']\n",
            " ['3']\n",
            " ['3']\n",
            " ['1']\n",
            " ['3']\n",
            " ['1']\n",
            " ['3']\n",
            " ['3']\n",
            " ['9']\n",
            " ['0']\n",
            " ['3']\n",
            " ['0']\n",
            " ['3']\n",
            " ['1']\n",
            " ['4']\n",
            " ['4']\n",
            " ['6']\n",
            " ['3']\n",
            " ['0']\n",
            " ['3']\n",
            " ['4']\n",
            " ['0']\n",
            " ['4']\n",
            " ['1']\n",
            " ['4']\n",
            " ['4']\n",
            " ['3']\n",
            " ['0']\n",
            " ['9']\n",
            " ['9']\n",
            " ['4']\n",
            " ['9']\n",
            " ['3']\n",
            " ['4']\n",
            " ['3']\n",
            " ['0']\n",
            " ['3']\n",
            " ['0']\n",
            " ['3']\n",
            " ['9']\n",
            " ['1']\n",
            " ['4']\n",
            " ['3']\n",
            " ['3']\n",
            " ['9']\n",
            " ['3']\n",
            " ['3']\n",
            " ['6']\n",
            " ['0']\n",
            " ['3']\n",
            " ['3']\n",
            " ['4']\n",
            " ['3']\n",
            " ['3']\n",
            " ['4']\n",
            " ['1']\n",
            " ['0']\n",
            " ['6']\n",
            " ['9']\n",
            " ['3']\n",
            " ['3']\n",
            " ['4']\n",
            " ['3']\n",
            " ['3']\n",
            " ['0']\n",
            " ['3']]\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5015 - loss: 2.0717\n",
            "[2.0788967609405518, 0.4699999988079071]\n"
          ]
        }
      ],
      "source": [
        "# Initialize the image classifier.\n",
        "clf = ak.ImageClassifier(overwrite=True, max_trials=1)\n",
        "# Feed the image classifier with training data.\n",
        "clf.fit(x_train, y_train, epochs=1)\n",
        "\n",
        "\n",
        "# Predict with the best model.\n",
        "predicted_y = clf.predict(x_test)\n",
        "print(predicted_y)\n",
        "\n",
        "\n",
        "# Evaluate the best model with testing data.\n",
        "print(clf.evaluate(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M5Oe9-UmbeV"
      },
      "source": [
        "## Validation Data\n",
        "By default, AutoKeras use the last 20% of training data as validation data. As\n",
        "shown in the example below, you can use validation_split to specify the\n",
        "percentage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5QnvJ0cmbeV"
      },
      "outputs": [],
      "source": [
        "clf.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    # Split the training data and use the last 15% as validation data.\n",
        "    validation_split=0.15,\n",
        "    epochs=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jyLnM1zmbeV"
      },
      "source": [
        "You can also use your own validation set instead of splitting it from the\n",
        "training data with validation_data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjI_P__0mbeV"
      },
      "outputs": [],
      "source": [
        "split = 50000\n",
        "x_val = x_train[split:]\n",
        "y_val = y_train[split:]\n",
        "x_train = x_train[:split]\n",
        "y_train = y_train[:split]\n",
        "clf.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    # Use your own validation set.\n",
        "    validation_data=(x_val, y_val),\n",
        "    epochs=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5HLILixmbeV"
      },
      "source": [
        "## Customized Search Space\n",
        "For advanced users, you may customize your search space by using AutoModel\n",
        "instead of ImageClassifier. You can configure the ImageBlock for some\n",
        "high-level configurations, e.g., block_type for the type of neural network to\n",
        "search, normalize for whether to do data normalization, augment for whether to\n",
        "do data augmentation. You can also do not specify these arguments, which would\n",
        "leave the different choices to be tuned automatically. See the following\n",
        "example for detail.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ng0Y55uImbeV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1cea803-08e6-460d-91e3-cb2bbb0d5eda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 Complete [00h 01m 01s]\n",
            "val_loss: 11939011584.0\n",
            "\n",
            "Best val_loss So Far: 11939011584.0\n",
            "Total elapsed time: 00h 01m 01s\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1s/step - accuracy: 0.0653 - loss: 12.8215\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d5e164f26e0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "input_node = ak.ImageInput()\n",
        "output_node = ak.ImageBlock(\n",
        "    # Only search ResNet architectures.\n",
        "    block_type=\"resnet\",\n",
        "    # Normalize the dataset.\n",
        "    normalize=True,\n",
        "    # Do not do data augmentation.\n",
        "    augment=False,\n",
        ")(input_node)\n",
        "output_node = ak.ClassificationHead()(output_node)\n",
        "clf = ak.AutoModel(\n",
        "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
        ")\n",
        "clf.fit(x_train, y_train, epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrXhaUWwmbeV"
      },
      "source": [
        "The usage of AutoModel is similar to the functional API of Keras. Basically, you\n",
        "are building a graph, whose edges are blocks and the nodes are intermediate\n",
        "outputs of blocks. To add an edge from input_node to output_node with\n",
        "output_node = ak.[some_block]([block_args])(input_node).\n",
        "\n",
        "You can even also use more fine grained blocks to customize the search space\n",
        "even further. See the following example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXqTFS7YmbeV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cfecdea-3de1-400c-d1b5-8a29940d3c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 Complete [00h 00m 51s]\n",
            "val_loss: 2.345547914505005\n",
            "\n",
            "Best val_loss So Far: 2.345547914505005\n",
            "Total elapsed time: 00h 00m 51s\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - accuracy: 0.1790 - loss: 2.5820\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d5e0ecce3b0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "input_node = ak.ImageInput()\n",
        "output_node = ak.Normalization()(input_node)\n",
        "output_node = ak.ImageAugmentation(horizontal_flip=False)(output_node)\n",
        "output_node = ak.ResNetBlock(version=\"v2\")(output_node)\n",
        "output_node = ak.ClassificationHead()(output_node)\n",
        "clf = ak.AutoModel(\n",
        "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
        ")\n",
        "clf.fit(x_train, y_train, epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg69pEMVmbeW"
      },
      "source": [
        "## Data Format\n",
        "The AutoKeras ImageClassifier is quite flexible for the data format.\n",
        "\n",
        "For the image, it accepts data formats both with and without the channel\n",
        "dimension. The images in the MNIST dataset do not have the channel dimension.\n",
        "Each image is a matrix with shape (28, 28). AutoKeras also accepts images of\n",
        "three dimensions with the channel dimension at last, e.g., (32, 32, 3), (28,\n",
        "28, 1).\n",
        "\n",
        "For the classification labels, AutoKeras accepts both plain labels, i.e.\n",
        "strings or integers, and one-hot encoded encoded labels, i.e. vectors of 0s and\n",
        "1s.\n",
        "\n",
        "So if you prepare your data in the following way, the ImageClassifier should\n",
        "still work.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dkXYnt4mbeW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13eab144-c382-42ce-d459-0fac8bd9002e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(60000, 10)\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape the images to have the channel dimension.\n",
        "x_train = x_train.reshape(x_train.shape + (1,))\n",
        "x_test = x_test.reshape(x_test.shape + (1,))\n",
        "\n",
        "# One-hot encode the labels.\n",
        "eye = np.eye(10)\n",
        "y_train = eye[y_train]\n",
        "y_test = eye[y_test]\n",
        "\n",
        "print(x_train.shape)  # (60000, 28, 28, 1)\n",
        "print(y_train.shape)  # (60000, 10)\n",
        "print(y_train[:3])\n",
        "# array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
        "#        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "#        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG9k2XoambeW"
      },
      "source": [
        "We also support using tf.data.Dataset format for the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K67qMrXpmbeW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2534519b-3c8d-45ad-d363-f46ed570caef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 Complete [00h 02m 31s]\n",
            "val_loss: 0.06477672606706619\n",
            "\n",
            "Best val_loss So Far: 0.06477672606706619\n",
            "Total elapsed time: 00h 02m 31s\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 85ms/step - accuracy: 0.9044 - loss: 0.3052\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.9769 - loss: 0.0708\n",
            "[0.058789562433958054, 0.9807999730110168]\n"
          ]
        }
      ],
      "source": [
        "train_set = tf.data.Dataset.from_tensor_slices(((x_train,), (y_train,)))\n",
        "test_set = tf.data.Dataset.from_tensor_slices(((x_test,), (y_test,)))\n",
        "\n",
        "clf = ak.ImageClassifier(overwrite=True, max_trials=1)\n",
        "# Feed the tensorflow Dataset to the classifier.\n",
        "clf.fit(train_set, epochs=1)\n",
        "# Predict with the best model.\n",
        "predicted_y = clf.predict(test_set)\n",
        "# Evaluate the best model with testing data.\n",
        "print(clf.evaluate(test_set))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkO8mqcHmbeW"
      },
      "source": [
        "## Reference\n",
        "[ImageClassifier](/image_classifier),\n",
        "[AutoModel](/auto_model/#automodel-class),\n",
        "[ImageBlock](/block/#imageblock-class),\n",
        "[Normalization](/block/#normalization-class),\n",
        "[ImageAugmentation](/block/#image-augmentation-class),\n",
        "[ResNetBlock](/block/#resnetblock-class),\n",
        "[ImageInput](/node/#imageinput-class),\n",
        "[ClassificationHead](/block/#classificationhead-class).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}